{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOApJlebzJSx8GdARcFl/XY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreeya1810/Battleship/blob/main/ds_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "gIoa8bjAHzAT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RNVejjRjIHLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8687ec9-0f1f-4b47-97fd-43388dfe14e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build(path):\n",
        "  newpath = path + \"/data\"\n",
        "\n",
        "\n",
        "  if not os.path.exists(newpath):\n",
        "    print(\"creating new directory...\")\n",
        "\n",
        "    os.makedirs(newpath)\n",
        "\n",
        "    path1 = path + \"/downSyndrome\"\n",
        "    path2 = path + \"/healty\"\n",
        "\n",
        "\n",
        "    files = os.listdir(path1)\n",
        "    for file in files:\n",
        "      shutil.copy2(os.path.join(path1, file), newpath)\n",
        "\n",
        "\n",
        "    files = os.listdir(path2)\n",
        "    for file in files:\n",
        "      shutil.copy2(os.path.join(path2, file), newpath)\n",
        "\n",
        "  else:\n",
        "    print(\"data already exists\")\n",
        "\n",
        "\n",
        "  data = os.listdir(newpath)\n",
        "  random.shuffle(data)\n",
        "  split_1 = int(0.8 * len(data))\n",
        "  split_2 = int(0.9 * len(data))\n",
        "  train = data[:split_1]\n",
        "  valid = data[split_1:split_2]\n",
        "  test = data[split_2:]\n",
        "\n",
        "\n",
        "  return train, valid, test"
      ],
      "metadata": {
        "id": "eHNDSHVnYEgV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/archive\"\n",
        "data = build(path)\n",
        "\n",
        "\n",
        "train_labels = []\n",
        "val_labels = []\n",
        "test_labels = []\n",
        "\n",
        "\n",
        "train, val, test = data"
      ],
      "metadata": {
        "id": "G6DgAdhTYsiT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54593554-09a4-466e-ea8a-d39e1c289555"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating new directory...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for path in train:\n",
        "    if \"down\" in path:\n",
        "      train_labels.append(1)\n",
        "    else:\n",
        "      train_labels.append(0)"
      ],
      "metadata": {
        "id": "EFurC3p7ZIGc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in test:\n",
        "  if \"down\" in path:\n",
        "    test_labels.append(1)\n",
        "  else:\n",
        "    test_labels.append(0)"
      ],
      "metadata": {
        "id": "OJXT5wKfZ6F3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in val:\n",
        "  if \"down\" in path:\n",
        "    val_labels.append(1)\n",
        "  else:\n",
        "    val_labels.append(0)"
      ],
      "metadata": {
        "id": "NFbKhQyiaaHU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "base_path = '/content/drive/MyDrive/archive/processed_data/'\n",
        "\n",
        "if not os.path.exists(base_path):\n",
        "  os.makedirs(base_path)"
      ],
      "metadata": {
        "id": "eadlVeAWa1fv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_processed_imgs(images, path, labels):\n",
        "  data_path = base_path + path\n",
        "  if not os.path.exists(data_path):\n",
        "    os.makedirs(data_path)\n",
        "\n",
        "  downSyndrome_path = os.path.join(data_path, \"downSyndrome\")\n",
        "  healthy_path = os.path.join(data_path, \"healthy\")\n",
        "\n",
        "  if not os.path.exists(downSyndrome_path):\n",
        "    os.makedirs(downSyndrome_path)\n",
        "  if not os.path.exists(healthy_path):\n",
        "    os.makedirs(healthy_path)\n",
        "\n",
        "  for index, image in enumerate(images):\n",
        "    if image is None or image.size == 0:\n",
        "      print(f\"Skipping image {index} due to zero size.\")\n",
        "      continue\n",
        "\n",
        "    if index >= len(labels):\n",
        "      print(f\"Skipping image {index} because label does not exist.\")\n",
        "      continue\n",
        "\n",
        "    normalized_image = (image - image.min()) / (image.max() - image.min()) * 255\n",
        "    im = Image.fromarray(normalized_image.astype('uint8'))\n",
        "\n",
        "\n",
        "    if labels[index] == 0:\n",
        "      im.save(os.path.join(healthy_path, f'{index}.png'))\n",
        "    else:\n",
        "      im.save(os.path.join(downSyndrome_path, f'{index}.png'))"
      ],
      "metadata": {
        "id": "R6egwjS_bK8p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For SSD\n",
        "def ssd(dir, image):\n",
        "  image = cv2.imread(dir + image)\n",
        "  detector = cv2.dnn.readNetFromCaffe(\"/content/deploy.prototxt.txt\",\"/content/res10_300x300_ssd_iter_140000.caffemodel\")\n",
        "  img_blob = cv2.dnn.blobFromImage(image)\n",
        "\n",
        "  detector.setInput(img_blob)\n",
        "  detections = detector.forward()\n",
        "  detections = detections[0][0]\n",
        "\n",
        "\n",
        "  df = pd.DataFrame(detections, columns=[\"img_id\", \"is_face\", \"confidence\", \"left\", \"top\", \"right\", \"bottom\"])\n",
        "  df = df[df[\"is_face\"]==1]\n",
        "  df = df[df[\"confidence\"] > 0.9]\n",
        "\n",
        "\n",
        "  for index, instance in df.iterrows():\n",
        "    left = int(instance['left'] * 300)\n",
        "    right = int(instance['right'] * 300)\n",
        "    top = int(instance['top'] * 300)\n",
        "    bottom = int(instance['bottom'] * 300)\n",
        "\n",
        "\n",
        "    if bottom <= 300 and right <= 300:\n",
        "      image = image[top:bottom, left:right]\n",
        "    return image"
      ],
      "metadata": {
        "id": "HiuEXwfTcy_C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ssd_train = []\n",
        "ssd_val = []\n",
        "ssd_test = []\n",
        "dir = \"/content/drive/MyDrive/archive/data/\"\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/archive/processed_data/'\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "  for image in train:\n",
        "    if image is not None:\n",
        "      ssd_train.append(ssd(dir, image))\n",
        "  save_processed_imgs(ssd_train, 'train', train_labels)\n",
        "\n",
        "  for image in val:\n",
        "    if image is not None:\n",
        "      ssd_val.append(ssd(dir, image))\n",
        "  save_processed_imgs(ssd_val, 'val', val_labels)\n",
        "\n",
        "  for image in test:\n",
        "    if image is not None:\n",
        "      ssd_test.append(ssd(dir, image))\n",
        "  save_processed_imgs(ssd_test, 'test', test_labels)\n",
        "\n",
        "else:\n",
        "  print(\"processed images already present.\")"
      ],
      "metadata": {
        "id": "jRhgbBDzdztU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675185a2-8d98-4836-8cfd-ed47b0545af6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping image 52 due to zero size.\n",
            "Skipping image 123 due to zero size.\n",
            "Skipping image 237 due to zero size.\n",
            "Skipping image 368 due to zero size.\n",
            "Skipping image 560 due to zero size.\n",
            "Skipping image 604 due to zero size.\n",
            "Skipping image 622 due to zero size.\n",
            "Skipping image 657 due to zero size.\n",
            "Skipping image 696 due to zero size.\n",
            "Skipping image 704 due to zero size.\n",
            "Skipping image 898 due to zero size.\n",
            "Skipping image 955 due to zero size.\n",
            "Skipping image 1100 due to zero size.\n",
            "Skipping image 1109 due to zero size.\n",
            "Skipping image 1157 due to zero size.\n",
            "Skipping image 1206 due to zero size.\n",
            "Skipping image 1375 due to zero size.\n",
            "Skipping image 1548 due to zero size.\n",
            "Skipping image 1566 due to zero size.\n",
            "Skipping image 1667 due to zero size.\n",
            "Skipping image 1684 due to zero size.\n",
            "Skipping image 1750 due to zero size.\n",
            "Skipping image 1916 due to zero size.\n",
            "Skipping image 1927 due to zero size.\n",
            "Skipping image 2054 due to zero size.\n",
            "Skipping image 2093 due to zero size.\n",
            "Skipping image 2115 due to zero size.\n",
            "Skipping image 2132 due to zero size.\n",
            "Skipping image 2156 due to zero size.\n",
            "Skipping image 2169 due to zero size.\n",
            "Skipping image 2174 due to zero size.\n",
            "Skipping image 2184 due to zero size.\n",
            "Skipping image 2248 due to zero size.\n",
            "Skipping image 2272 due to zero size.\n",
            "Skipping image 54 due to zero size.\n",
            "Skipping image 136 due to zero size.\n",
            "Skipping image 168 due to zero size.\n",
            "Skipping image 182 due to zero size.\n",
            "Skipping image 191 due to zero size.\n",
            "Skipping image 225 due to zero size.\n",
            "Skipping image 231 due to zero size.\n",
            "Skipping image 17 due to zero size.\n",
            "Skipping image 71 due to zero size.\n",
            "Skipping image 126 due to zero size.\n",
            "Skipping image 193 due to zero size.\n",
            "Skipping image 197 due to zero size.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For MTCNN\n",
        "import dlib\n",
        "from imutils import paths\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import face_recognition\n",
        "\n",
        "\n",
        "def mtcnn(dir, image):\n",
        "  image = face_recognition.load_image_file(dir + image)\n",
        "\n",
        "  detector = MTCNN()\n",
        "  face_locations = detector.detect_faces(image)\n",
        "\n",
        "  for face in zip(face_locations):\n",
        "    x,y,w,h = face[0]['box']\n",
        "    landmarks = face[0]\n",
        "\n",
        "  image = image[y:y+h, x:x+w]\n",
        "  return image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "lxxowkn0d-Tf",
        "outputId": "9dbf7c57-35b8-4c88-b832-939b4cff290f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-install-nj6k7_al/dlib_dd113b177fa647df963e4f896c088a8b/dlib/cuda/gpu_data.cpp:204. code: 35, reason: CUDA driver version is insufficient for CUDA runtime version",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-920a94a4be48>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmtcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMTCNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1.2.3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_face_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_landmarks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcnn_face_detection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detector_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcnn_face_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detection_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_face_detection_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mface_recognition_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_recognition_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-install-nj6k7_al/dlib_dd113b177fa647df963e4f896c088a8b/dlib/cuda/gpu_data.cpp:204. code: 35, reason: CUDA driver version is insufficient for CUDA runtime version"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mtcnn_train = []\n",
        "mtcnn_val = []\n",
        "mtcnn_test = []\n",
        "dir = \"/content/drive/MyDrive/archive/data/\"\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/archive/processed_data/'\n",
        "\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "  for image in train:\n",
        "    if image is not None:\n",
        "      mtcnn_train.append(mtcnn(dir, image))\n",
        "  save_processed_imgs(mtcnn_train, 'train', train_labels)\n",
        "\n",
        "  for image in val:\n",
        "    if image is not None:\n",
        "      mtcnn_val.append(mtcnn(dir, image))\n",
        "  save_processed_imgs(mtcnn_val, 'val', val_labels)\n",
        "\n",
        "  for image in test:\n",
        "    if image is not None:\n",
        "      mtcnn_test.append(mtcnn(dir, image))\n",
        "  save_processed_imgs(mtcnn_test, 'test', test_labels)\n",
        "\n",
        "else:\n",
        "  print(\"processed images already present.\")"
      ],
      "metadata": {
        "id": "by09QM9Ib5Rn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f1485c-b89f-4dbe-bc43-1347f68e3d45"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed images already present.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification Model\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "viRtXEkxeMVo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalise(image):\n",
        "  image = cv2.resize(image, (224, 224))\n",
        "\n",
        "  if len(image.shape) == 2: # If image is grayscale, convert to RGB\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "  image = img_to_array(image)\n",
        "  image = image / 255.0\n",
        "  return image"
      ],
      "metadata": {
        "id": "vpggcjn0fA5-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen=ImageDataGenerator(preprocessing_function = normalise)\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function = normalise)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "directory=\"/content/drive/MyDrive/archive/processed_data/train\",\n",
        "target_size=(224, 224),\n",
        "batch_size=8,\n",
        "class_mode=\"binary\"\n",
        ")\n",
        "\n",
        "val_generator = validation_datagen.flow_from_directory(\n",
        "directory=\"/content/drive/MyDrive/archive/processed_data/val\",\n",
        "target_size=(224, 224),\n",
        "batch_size=8,\n",
        "class_mode=\"binary\"\n",
        ")\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "monitor=\"val_accuracy\",\n",
        "min_delta=0.05,\n",
        "patience=15,\n",
        "verbose=1,\n",
        "mode=\"max\",\n",
        "baseline=None,\n",
        "restore_best_weights=True\n",
        ")\n",
        "\n",
        "METRICS = [\n",
        "tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "tf.keras.metrics.Precision(name='precision'),\n",
        "tf.keras.metrics.Recall(name='recall')\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCpgrwOye1J7",
        "outputId": "1b8b0dc7-f8a5-4c0c-c9fc-6b26724a4334"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2365 images belonging to 2 classes.\n",
            "Found 293 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using ResNet50\n",
        "import os\n",
        "\n",
        "path_checkpoint = \"model_cp_resnet.ckpt\"\n",
        "directory_checkpoint = os.path.dirname(path_checkpoint)\n",
        "\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=path_checkpoint,\n",
        "save_weights_only=True,\n",
        "verbose=1)\n",
        "\n",
        "# Define input layer\n",
        "input_layer = tf.keras.layers.Input(shape=(224, 224, 3), name='image_input')\n",
        "\n",
        "# Create ResNet50 Model\n",
        "resnet = tf.keras.applications.ResNet50(\n",
        "include_top=False,\n",
        "weights='imagenet',\n",
        "input_tensor=input_layer,\n",
        "pooling=None\n",
        ")\n",
        "\n",
        "# Freeze ResNet50 layers\n",
        "for layer in resnet.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Add custom classification layers\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(resnet.output)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(8, activation='relu')(x)\n",
        "predictions = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create final model\n",
        "model = tf.keras.models.Model(inputs=input_layer, outputs=predictions)"
      ],
      "metadata": {
        "id": "m5DEFMrWfKih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e449445-7c0a-4c17-9221-037e4273fbb5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.0001), loss='binary_crossentropy', metrics=METRICS)\n",
        "\n",
        "history = model.fit_generator(\n",
        "train_generator,\n",
        "steps_per_epoch=len(train_generator),\n",
        "epochs=100,\n",
        "validation_data=val_generator,\n",
        "validation_steps=len(val_generator),\n",
        "callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4H5xLsQcdCj",
        "outputId": "a3c911ae-3dc3-4609-db3b-878e8e292d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-273ea5570688>:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "296/296 [==============================] - 545s 2s/step - loss: 0.7012 - accuracy: 0.5019 - precision: 0.5070 - recall: 0.4245 - val_loss: 0.6926 - val_accuracy: 0.5392 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/100\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.6955 - accuracy: 0.5121 - precision: 0.5183 - recall: 0.4505"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='val')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "w-RsPA1kcnaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using custom CNN Model\n",
        "\n",
        "import os\n",
        "\n",
        "path_checkpoint = \"model_cp_custom.ckpt\"\n",
        "directory_checkpoint = os.path.dirname(path_checkpoint)\n",
        "\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=path_checkpoint,\n",
        "save_weights_only=True,\n",
        "verbose=1)"
      ],
      "metadata": {
        "id": "qBOyTbymc5wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten()) # this converts our 3D feature maps to 1D feature vectors\n",
        "model.add (Dense (64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "optimizer='rmsprop' ,\n",
        "metrics=METRICS)"
      ],
      "metadata": {
        "id": "cjtNu6vjc8oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "train_generator,\n",
        "steps_per_epoch=250,\n",
        "epochs=100,\n",
        "validation_data=val_generator,\n",
        "validation_steps=20,\n",
        "callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "_6c0ZgCfdGSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='val')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "fcFWGdWNdMIW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}